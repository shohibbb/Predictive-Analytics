# -*- coding: utf-8 -*-
"""Analisis Prediktif Performa Murid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YeCbGTBvjdejtnKfecpHqhy9nXUOa7vb

# Data Loading

## Dowload data

Data yang digunakan pada project ini adalah data terkait kebiasaan siswa yang bisa jadi berdampak pada kemampuan siswa, berasal dari kaggle dengan judul *Student Performance (Multiple Linear Regression)* berisi 10.000 sampel dan Performance Index sebagai Target Datanya
"""

# from google.colab import files
# files.upload()  # Upload kaggle.json yang tadi diunduh

# !mkdir -p ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !chmod 600 ~/.kaggle/kaggle.json

# #!/bin/bash
# !kaggle datasets download nikhil7280/student-performance-multiple-linear-regression
# !unzip student-performance-multiple-linear-regression.zip

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

df = pd.read_csv('/content/Student_Performance.csv')
df.head()

"""# Exploratory Data Analysis

Exploratory data dilakukan untuk melihat kondisi distribusi data baik yang bertipe kategorikal atau numerikal.

## Deskripsi Variabel
"""

df.info()

"""## Checking Missing, Duplicate Values and Outlier

Hasil pengecekan nilai yang hilang menunjukan bahwa tidak ada satupun kolom yang memiliki data yang hilang
"""

df.isnull().sum()

"""Sedangkan untuk pengecekan data duplikat menunjukan bahwa ada 127 data duplikat yang kemudian bisa dihilangkan."""

print(df.duplicated().sum())
df.drop_duplicates(inplace=True)
print(df.duplicated().sum())

"""EDA yang dilakukan untuk melihat kondisi dari setiap kolom yang ada seperti tipe data, jumlah sampel, nama kolom, mean, std dan masih banyak."""

df.describe()

target_column = 'Performance Index'

numerical_cols = df.select_dtypes(include='number').drop(columns=[target_column])

plt.figure(figsize=(12, 8))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(data=df, x=col, palette='Set2')
    plt.title(f'Boxplot of {col}')
    plt.tight_layout()

plt.show()

"""## Univariate Analysis

Univariate Analysis dilakukan untuk melihat distribusi satu kolom tanpa ada hubungan dengan kolom lain

Membuat diagram batang untuk melihat distribusi data kategorikal yaitu *Extracurricular Activities*. Diagram menunjukan bahwa persebaran data tersebut seimbang
"""

bar_data = df['Extracurricular Activities'].value_counts()

plt.figure(figsize=(8, 6))
sns.barplot(x=bar_data.index, y=bar_data.values)
plt.xlabel('Extracurricular Activities')
plt.ylabel('Count')
plt.title('Distribution of Extracurricular Activities')

"""Selanjutnya membuat histogram untuk melihat persebaran data numerikal. Berdasarkan bagan-bagan tersebut dapat dilihat bahwa tidak ada ketimpangan pada masing-masing data"""

plt.figure(figsize=(15, len(numerical_cols.columns) * 4))
for i, col in enumerate(numerical_cols.columns):
    plt.subplot(len(numerical_cols.columns), 1, i + 1)
    sns.histplot(df[col], kde=True, bins=20, color='skyblue')
    plt.title(f'Distribusi: {col}')
    plt.xlabel(col)
    plt.tight_layout()

plt.show()

"""## Multivariate Analysis

Multivariate Analysis dilakukan untuk melihat hubungan antara satu kolom dengan kolom lain
"""

target_column = 'Performance Index'

numerical_cols = df.select_dtypes(include='number').drop(columns=[target_column]).columns.tolist()

plt.figure(figsize=(12, 10))
corr = df[numerical_cols].corr()
sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title("Correlation Matrix Heatmap")
plt.show()

"""# Data Prepration

Menyiapkan Data untuk digunakan dalam proses pembangunan model machine learning

## Standarisasi

Berikut merupakan proses standarisasi untuk data-data numerikal yang terdapat pada dataset yang digunakan selain data target.
"""

scaler = MinMaxScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
df.head()

"""## Transformasi

Selanjutnya ada tranformasi data menggunakan label encoder untuk merubah data kategorikal yang diisi dengan nilai huruf contoh nya "yes" dan "no" menjadi angka yang setiap angka mewakilkan satu kategori
"""

label_encoder = LabelEncoder()
df['Extracurricular Activities'] = label_encoder.fit_transform(df['Extracurricular Activities'])
df.head()

"""## Data Splitting

Bertujuan untuk membagi data dengan rasio tertentu yang mana sebagian akan digunakan untuk melatih/membangun model machine learning sedangkan sebagian yang lain akan digunakan untuk menguji model yang sudah dibangun.
"""

X = df.drop(columns=[target_column])
y = df[target_column]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Model Development

Membangun model machine learning untuk data dengan data yang sudah disiapkan sebelumnya.
"""

rf_model = RandomForestRegressor()
rf_model.fit(X_train, y_train)

from xgboost import XGBRegressor
xgb_model = XGBRegressor()
xgb_model.fit(X_train, y_train)

"""# Evaluasi Model

mengevaluasi hasil kinerja model yang sudah dibangun menggunakan metrik


1.   Mean Square Error
2.   Mean Absolute Erro
3.   R-Squared
"""

import pandas as pd
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Inisialisasi list hasil evaluasi
results = []

# Evaluasi Random Forest
y_train_pred_rf = rf_model.predict(X_train)
y_test_pred_rf = rf_model.predict(X_test)

results.append({
    'Model': 'Random Forest',
    'Train MSE': mean_squared_error(y_train, y_train_pred_rf),
    'Test MSE': mean_squared_error(y_test, y_test_pred_rf),
    'Train MAE': mean_absolute_error(y_train, y_train_pred_rf),
    'Test MAE': mean_absolute_error(y_test, y_test_pred_rf),
    'Train R²': r2_score(y_train, y_train_pred_rf),
    'Test R²': r2_score(y_test, y_test_pred_rf)
})

# Evaluasi XGBoost
y_train_pred_xgb = xgb_model.predict(X_train)
y_test_pred_xgb = xgb_model.predict(X_test)

results.append({
    'Model': 'XGBoost',
    'Train MSE': mean_squared_error(y_train, y_train_pred_xgb),
    'Test MSE': mean_squared_error(y_test, y_test_pred_xgb),
    'Train MAE': mean_absolute_error(y_train, y_train_pred_xgb),
    'Test MAE': mean_absolute_error(y_test, y_test_pred_xgb),
    'Train R²': r2_score(y_train, y_train_pred_xgb),
    'Test R²': r2_score(y_test, y_test_pred_xgb)
})

# Buat DataFrame dari hasil
metrics_df = pd.DataFrame(results)

# Tampilkan
metrics_df.head()

"""Berdasarkan hasil dari tiap-tiap metriks pada data test, XGBoost menunjukan keunggulan yang dibuktikan dengan error yang lebih rendah pada MAE dan MSE dan R2 yang lebih tinggi"""

importance = xgb_model.feature_importances_

# Buat DataFrame
feat_importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': importance
}).sort_values(by='Importance', ascending=False)

# Tampilkan
feat_importance_df

"""fungsi feature_importances_ akan menampilkan nilai kepentingan masing-masing fitur pada dataset. disini kita lihat yang paling berpengaruh ke indeks performa adalah Previous Scores, kedua Hours Studied, dan terakhir sleep hours"""